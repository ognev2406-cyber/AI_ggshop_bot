import httpx
from typing import Optional, Dict, Any
import logging
from urllib.parse import urlparse
from config import OLLAMA_BASE_URL, OLLAMA_MODEL

logger = logging.getLogger(__name__)


class OllamaService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Ollama (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π AI)"""
    
    def __init__(self):
        self.base_url = OLLAMA_BASE_URL
        self.model = OLLAMA_MODEL
        self.client = httpx.AsyncClient(
            base_url=self.base_url,
            timeout=30.0
        )
        logger.info(f"‚úÖ –°–µ—Ä–≤–∏—Å Ollama –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.base_url}, –º–æ–¥–µ–ª—å: {self.model}")
    
    async def check_api_access(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama"""
        try:
            response = await self.client.get("/api/tags")
            if response.status_code == 200:
                logger.info("‚úÖ Ollama –¥–æ—Å—Ç—É–ø–µ–Ω")
                return True
            return False
        except Exception as e:
            logger.error(f"‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            return False
    
    async def generate_text(
        self, 
        prompt: str, 
        system_prompt: Optional[str] = None,
        temperature: float = 0.7
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Ollama"""
        try:
            messages = []
            
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            
            messages.append({"role": "user", "content": prompt})
            
            payload = {
                "model": self.model,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": temperature,
                    "num_predict": 1000
                }
            }
            
            logger.info(f"üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Ollama: {self.model}")
            
            response = await self.client.post(
                "/api/chat",
                json=payload,
                timeout=60.0
            )
            
            if response.status_code == 200:
                result = response.json()["message"]["content"]
                logger.info(f"‚úÖ –¢–µ–∫—Å—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω, –¥–ª–∏–Ω–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
                return result.strip()
            else:
                error_msg = f"–û—à–∏–±–∫–∞ Ollama: {response.status_code}"
                logger.error(error_msg)
                return f"‚ùå {error_msg}"
        
        except httpx.TimeoutException:
            logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞")
            return "‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"
    
    async def generate_image(
        self, 
        prompt: str,
        size: str = "1024x1024"
    ) -> Optional[str]:
        """Ollama –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏"""
        return "‚ö†Ô∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Stable Diffusion –∏–ª–∏ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å."
    
    async def list_models(self) -> list:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            response = await self.client.get("/api/tags")
            if response.status_code == 200:
                return [model["name"] for model in response.json().get("models", [])]
            return []
        except:
            return []


# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
ollama_service = OllamaService()